{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "from openai import AzureOpenAI\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery, QueryType, QueryCaptionType, QueryAnswerType, VectorFilterMode\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Environment setup\n",
    "load_dotenv()\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']\n",
    "key = os.getenv(\"AZURE_SEARCH_KEY\") \n",
    "false = True #Set to true to see more output information\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\") \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") \n",
    "model = \"ada002\"\n",
    "\n",
    "#Initialize AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_KEY'],  \n",
    "  api_version = \"2023-12-01-preview\"\n",
    "  )\n",
    "\n",
    "messages=[]\n",
    "\n",
    "def count_tokens(prompt) -> int:  \n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    token_sizes = len(encoding.encode(prompt))\n",
    "    return token_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_content=\"\"\n",
    "# system message\n",
    "system_message = f'''\n",
    "You are an assistant with knowledge of the following topics:\n",
    "1. IEC61131-3 languages\n",
    "2. Structured Text\n",
    "3. Function Block Diagram\n",
    "4. IEC61131-3 coding standards\n",
    "5. IEC61131-3 best practices\n",
    "6. IEC61131-3 coding guidelines\n",
    "7. IEC61131-3 programming\n",
    "8. IEC61131-3 programming languages\n",
    "9. Schneider Electric EcoStruxure Control Expert\n",
    "10. Schneider Electric EcoStruxure Machine Expert\n",
    "11. Schneider Electric EcoStruxure Machine Expert Libraries and Templates\n",
    "\n",
    "Your job is to generate small examples of code using exclusiveliy IEC61131-3 Structured Text base on user input.\n",
    "You can assume that all the code will be executed on a Schneider Electric EcoStruxure Control Expert or Schneider Electric EcoStruxure Machine Expert PLC and that all libraries are available.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_command(lib_name:str, fn_name:str, rag_info:str):\n",
    "  return f'''  \n",
    "    Generate a small program in IEC61131-3 that uses Scheneider Electric {lib_name} library to send an email using following parameters:\n",
    "    1. To: \"receiver@se.com\"\n",
    "    2. Subject: \"Test email\"\n",
    "    3. Body: \"This is a test email\"\n",
    "    4. From: \"sender@se.com\"\n",
    "\n",
    "    Authentication required.\n",
    "    Message should be sent with high priority.\n",
    "    Use Login to authenticate using \"corrado\" as user and \"p@ssw0rd123\" as password.\n",
    "    Verify that the email has been sent successfully, if not print the error message.\n",
    "\n",
    "    These are the information about the {fn_name} function from the {lib_name} library you have to use:\n",
    "    ```\n",
    "    {rag_info}\n",
    "    ```\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cell uses LLM to summarize RAG content, but looks like is not working since it strips out most of the important info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages=[]\n",
    "# messages.append({'role': 'system', 'content': \"You are an assistant expert in summarize code libraries documentation. Your goal is to summarize the user provided content removing not relevant information\"})\n",
    "# messages.append({'role': 'user', 'content': rag_content})  \n",
    "\n",
    "# token_count=count_tokens(rag_content);\n",
    "# print (f'Total input RAG tokens: {token_count}')     \n",
    "\n",
    "# openai_response = client.chat.completions.create(\n",
    "#         model=deployment,    \n",
    "#         messages = messages,\n",
    "#         temperature=0.3,\n",
    "#         max_tokens=800,\n",
    "#         top_p=0.95,\n",
    "#         frequency_penalty=0,\n",
    "#         presence_penalty=0,\n",
    "#         stop=None)\n",
    "\n",
    "# rag_content= openai_response.choices[0].message.content\n",
    "\n",
    "# token_count=count_tokens(rag_content);\n",
    "# print (f'Summarized RAG tokens: {token_count}') \n",
    "# messages=[]\n",
    "\n",
    "# # system message\n",
    "# system_message = f'''\n",
    "# You are an assistant with knowledge of the following topics:\n",
    "# 1. IEC61131-3 languages\n",
    "# 2. Structured Text\n",
    "# 3. Function Block Diagram\n",
    "# 4. IEC61131-3 coding standards\n",
    "# 5. IEC61131-3 best practices\n",
    "# 6. IEC61131-3 coding guidelines\n",
    "# 7. IEC61131-3 programming\n",
    "# 8. IEC61131-3 programming languages\n",
    "# 9. Schneider Electric EcoStruxure Control Expert\n",
    "# 10. Schneider Electric EcoStruxure Machine Expert\n",
    "# 11. Schneider Electric EcoStruxure Machine Expert Libraries and Templates\n",
    "\n",
    "# Your job is to generate small examples of code using exclusiveliy IEC61131-3 Structured Text base on user input.\n",
    "# You can assume that all the code will be executed on a Schneider Electric EcoStruxure Control Expert or Schneider Electric EcoStruxure Machine Expert PLC and that all libraries are available.\n",
    "\n",
    "# Use the following pieces of retrieved context to answer the question.\n",
    "# CONTEXT:\n",
    "# ```\n",
    "# {rag_content}\n",
    "# ```\n",
    "\n",
    "# '''\n",
    "\n",
    "# print(system_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_embeddings(text):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def get_from_RAG(query: str, max_results: int = 10, verbose: bool = False):    \n",
    "    search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "    vector_query = VectorizedQuery(vector= generate_embeddings(query), k_nearest_neighbors=max_results, fields=\"embedding\")\n",
    "    results = search_client.search(          \n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\",\"sourcefile\",\"content\"],\n",
    "        query_type=QueryType.SEMANTIC, \n",
    "        top=max_results,\n",
    "        semantic_configuration_name='default', \n",
    "        query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "        query_answer=QueryAnswerType.EXTRACTIVE        \n",
    "    )   \n",
    "    \n",
    "    rag_results=[]\n",
    "    if results :        \n",
    "        for result in results:\n",
    "            if verbose:            \n",
    "                print(f\"Id: {result['id']}\")\n",
    "                print(f\"Reranker Score: {result['@search.score']}\")\n",
    "                print(f\"Content: {result['content']}\")\n",
    "                print(f\"Sourcefile: {result['sourcefile']}\")                \n",
    "            rag_results.append(result['content'])                \n",
    "                \n",
    "    return rag_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theses are the user commands, edit and run them to see the different output considering that output also depends on code implemented into function (to be replaced by RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rag tokens: 1093\n",
      "Here is an example of how you can use the FB_SendEMail function block from the EmailHandling library to send an email:\n",
      "\n",
      "```iecst\n",
      "PROGRAM SendEmail\n",
      "VAR\n",
      "    EmailClient: SE_EMail.FB_SendEMail;\n",
      "    EmailCredentials: SE_EMail.ST_Credentials;\n",
      "    EmailMessage: SE_EMail.ST_Message;\n",
      "    EmailError: SE_EMail.ST_Error;\n",
      "    SendEmail: BOOL;\n",
      "END_VAR\n",
      "```\n",
      "\n",
      "In the initialization part of your program, you can set up the email credentials and message:\n",
      "\n",
      "```iecst\n",
      "EmailCredentials.sUser := 'corrado';\n",
      "EmailCredentials.sPassword := 'p@ssw0rd123';\n",
      "\n",
      "EmailMessage.sFrom := 'sender@se.com';\n",
      "EmailMessage.sTo := 'receiver@se.com';\n",
      "EmailMessage.sSubject := 'Test email';\n",
      "EmailMessage.sBody := 'This is a test email';\n",
      "EmailMessage.ePriority := SE_EMail.E_Priority#high;\n",
      "\n",
      "SendEmail := TRUE;\n",
      "```\n",
      "\n",
      "Then, in the cyclic part of your program, you can use the FB_SendEMail function block to send the email:\n",
      "\n",
      "```iecst\n",
      "EmailClient(\n",
      "    xEnable := SendEmail,\n",
      "    stCredentials := EmailCredentials,\n",
      "    pbyMessage := ADR(EmailMessage),\n",
      "    dwMessageSize := SIZEOF(EmailMessage),\n",
      "    xTLS := TRUE,\n",
      "    sServer := 'smtp.se.com',\n",
      "    wPort := 587,\n",
      "    tTimeout := T#30S\n",
      ");\n",
      "\n",
      "IF EmailClient.q_xError THEN\n",
      "    // Error handling\n",
      "    SendEmail := FALSE;\n",
      "    EmailError := EmailClient.stError;\n",
      "    // Print the error message\n",
      "    PRINTF('Error sending email: %s', EmailError.sMessage);\n",
      "END_IF;\n",
      "```\n",
      "\n",
      "Please note that you need to replace 'smtp.se.com' with the actual SMTP server of your email provider. Also, the port number (587 in this case) might be different depending on your email provider and whether you are using SSL/TLS or not.\n"
     ]
    }
   ],
   "source": [
    "lib_name=\"EmailHandling\"\n",
    "fn_name=\"FB_SendEmail\"\n",
    "\n",
    "query = f\"Find all the info related to the {fn_name} function in the {lib_name} library.\"\n",
    "rag_results = get_from_RAG(query, max_results=5, verbose=False)\n",
    "rag_data='n'.join(rag_results)\n",
    "\n",
    "token_count=count_tokens(rag_data);\n",
    "print (f'Total rag tokens: {token_count}')  \n",
    "\n",
    "# uncomment to remove rag_data\n",
    "#rag_data=\"\"\n",
    "  \n",
    "user_command=get_user_command(lib_name, fn_name, rag_data)\n",
    "\n",
    "messages.append({'role': 'system', 'content': system_message})\n",
    "messages.append({'role': 'user', 'content': user_command})  \n",
    "\n",
    "openai_response = client.chat.completions.create(\n",
    "        model=deployment,    \n",
    "        messages = messages,\n",
    "        temperature=0.3,\n",
    "        max_tokens=800,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None)\n",
    "result= openai_response.choices[0].message\n",
    "\n",
    "print (result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptflow",
   "language": "python",
   "name": "promptflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
